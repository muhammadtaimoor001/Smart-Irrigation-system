{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12MD_R9iDURqL9vJTTsF32KwUkup8LLOM",
      "authorship_tag": "ABX9TyOViUKZSXq/YLlIrVnVQOtn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadtaimoor001/Smart-Irrigation-system/blob/master/Task1Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0DWK2kiOicSH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/water/toughestsport.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "hfyT1UX6i6t1",
        "outputId": "eaaae2d8-6a34-42cd-b946-d812040f97ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        SPORT  Endurance  Strength  Power  Speed  Agility  Flexibility  Nerve  \\\n",
              "0      Boxing       8.63      8.13   8.63   6.38     6.25         4.38   8.88   \n",
              "1  Ice Hockey       7.25      7.13   7.88   7.75     7.63         4.88   6.00   \n",
              "2    Football       5.38      8.63   8.13   7.13     6.38         4.38   7.25   \n",
              "3  Basketball       7.38      6.25   6.50   7.25     8.13         5.63   4.13   \n",
              "\n",
              "   Durability  Hand-eye coordination  Analytical Aptitude   Total  Rank  \n",
              "0        8.50                    7.0                 5.63  72.375     1  \n",
              "1        8.25                    7.5                 7.50  71.750     2  \n",
              "2        8.50                    5.5                 7.13  68.375     3  \n",
              "3        7.75                    7.5                 7.38  67.875     4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7500fb18-8055-4f98-8597-0ddd550eb5ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SPORT</th>\n",
              "      <th>Endurance</th>\n",
              "      <th>Strength</th>\n",
              "      <th>Power</th>\n",
              "      <th>Speed</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Flexibility</th>\n",
              "      <th>Nerve</th>\n",
              "      <th>Durability</th>\n",
              "      <th>Hand-eye coordination</th>\n",
              "      <th>Analytical Aptitude</th>\n",
              "      <th>Total</th>\n",
              "      <th>Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Boxing</td>\n",
              "      <td>8.63</td>\n",
              "      <td>8.13</td>\n",
              "      <td>8.63</td>\n",
              "      <td>6.38</td>\n",
              "      <td>6.25</td>\n",
              "      <td>4.38</td>\n",
              "      <td>8.88</td>\n",
              "      <td>8.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.63</td>\n",
              "      <td>72.375</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ice Hockey</td>\n",
              "      <td>7.25</td>\n",
              "      <td>7.13</td>\n",
              "      <td>7.88</td>\n",
              "      <td>7.75</td>\n",
              "      <td>7.63</td>\n",
              "      <td>4.88</td>\n",
              "      <td>6.00</td>\n",
              "      <td>8.25</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.50</td>\n",
              "      <td>71.750</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Football</td>\n",
              "      <td>5.38</td>\n",
              "      <td>8.63</td>\n",
              "      <td>8.13</td>\n",
              "      <td>7.13</td>\n",
              "      <td>6.38</td>\n",
              "      <td>4.38</td>\n",
              "      <td>7.25</td>\n",
              "      <td>8.50</td>\n",
              "      <td>5.5</td>\n",
              "      <td>7.13</td>\n",
              "      <td>68.375</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basketball</td>\n",
              "      <td>7.38</td>\n",
              "      <td>6.25</td>\n",
              "      <td>6.50</td>\n",
              "      <td>7.25</td>\n",
              "      <td>8.13</td>\n",
              "      <td>5.63</td>\n",
              "      <td>4.13</td>\n",
              "      <td>7.75</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.38</td>\n",
              "      <td>67.875</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7500fb18-8055-4f98-8597-0ddd550eb5ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7500fb18-8055-4f98-8597-0ddd550eb5ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7500fb18-8055-4f98-8597-0ddd550eb5ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26d26fa5-760b-433c-9a7d-8ec5c34fa262\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26d26fa5-760b-433c-9a7d-8ec5c34fa262')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26d26fa5-760b-433c-9a7d-8ec5c34fa262 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 60,\n  \"fields\": [\n    {\n      \"column\": \"SPORT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Boxing\",\n          \"Martial Arts\",\n          \"Skateboarding\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Endurance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0942167069859816,\n        \"min\": 1.0,\n        \"max\": 9.63,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          1.38,\n          7.63,\n          9.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.715357056273846,\n        \"min\": 1.0,\n        \"max\": 9.25,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          1.63,\n          6.88,\n          5.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.980397402052552,\n        \"min\": 1.25,\n        \"max\": 9.75,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          3.38,\n          2.5,\n          7.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.266403482560577,\n        \"min\": 0.63,\n        \"max\": 9.88,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          1.13,\n          0.88,\n          5.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Agility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.92727303616592,\n        \"min\": 1.0,\n        \"max\": 8.25,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          1.63,\n          1.13,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flexibility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7043687550255504,\n        \"min\": 1.13,\n        \"max\": 10.0,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          2.38,\n          5.5,\n          3.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Nerve\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.442645475893699,\n        \"min\": 0.88,\n        \"max\": 9.88,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          2.88,\n          4.5,\n          3.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Durability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.882102224989582,\n        \"min\": 0.75,\n        \"max\": 8.5,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          3.25,\n          4.25,\n          6.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hand-eye coordination\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9663279824239082,\n        \"min\": 1.88,\n        \"max\": 9.25,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          3.88,\n          6.75,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Analytical Aptitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.576829974461921,\n        \"min\": 2.25,\n        \"max\": 7.5,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          2.63,\n          5.88,\n          3.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.17051928013027,\n        \"min\": 14.5,\n        \"max\": 72.375,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          53.125,\n          27.5,\n          30.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 1,\n        \"max\": 60,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          23,\n          56,\n          55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "path = \"/content/drive/MyDrive/water/toughestsport.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# Display the first 4 rows of the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df.head(4))\n",
        "\n",
        "# Assuming there is a column named 'text' that we want to preprocess\n",
        "# You can replace 'text' with the actual column name containing text data\n",
        "text_column = 'text'\n",
        "\n",
        "# Tokenization: Split the text into words and sentences\n",
        "df['tokenized_words'] = df[text_column].apply(word_tokenize)\n",
        "df['tokenized_sentences'] = df[text_column].apply(sent_tokenize)\n",
        "\n",
        "# Stemming: Reduce words to their root form using Porter Stemmer\n",
        "porter = PorterStemmer()\n",
        "df['stemmed_words'] = df['tokenized_words'].apply(lambda words: [porter.stem(word) for word in words])\n",
        "\n",
        "# Lemmatization: Further reduce the stemmed words by considering their context using WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['lemmatized_words'] = df['stemmed_words'].apply(lambda words: [lemmatizer.lemmatize(word) for word in words])\n",
        "\n",
        "# Stop Word Removal: Eliminate common words that may not be useful for analysis\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['filtered_words'] = df['lemmatized_words'].apply(lambda words: [word for word in words if word.lower() not in stop_words])\n",
        "\n",
        "# Display the preprocessed columns\n",
        "print(\"\\nPreprocessed DataFrame:\")\n",
        "print(df[['tokenized_words', 'stemmed_words', 'lemmatized_words', 'filtered_words']].head(4))\n",
        "\n",
        "# Discussion on the impact of each preprocessing step\n",
        "print(\"\\nDiscussion on the impact of each preprocessing step:\")\n",
        "print(\"\\nTokenization:\")\n",
        "print(\"Tokenization splits the text into smaller units such as words and sentences. This is the fundamental step for any text processing task as it breaks down the text into manageable pieces.\")\n",
        "\n",
        "print(\"\\nStemming:\")\n",
        "print(\"Stemming reduces words to their root form. This helps in reducing the vocabulary size and focuses on the core meaning of the words. However, stemming can sometimes produce non-dictionary words (e.g., 'running' becomes 'run').\")\n",
        "\n",
        "print(\"\\nLemmatization:\")\n",
        "print(\"Lemmatization reduces words to their base or dictionary form. It is more accurate than stemming as it considers the context of the word. For example, 'better' is lemmatized to 'good'. This step is crucial for better understanding and analysis of the text.\")\n",
        "\n",
        "print(\"\\nStop Word Removal:\")\n",
        "print(\"Stop word removal eliminates common words that do not carry significant meaning and are often redundant in text analysis. This step helps in focusing on the more meaningful words in the corpus.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "WGn8qUnOkYEB",
        "outputId": "a1aa06d4-086c-4def-f486-e9bc7ad9e53f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "        SPORT  Endurance  Strength  Power  Speed  Agility  Flexibility  Nerve  \\\n",
            "0      Boxing       8.63      8.13   8.63   6.38     6.25         4.38   8.88   \n",
            "1  Ice Hockey       7.25      7.13   7.88   7.75     7.63         4.88   6.00   \n",
            "2    Football       5.38      8.63   8.13   7.13     6.38         4.38   7.25   \n",
            "3  Basketball       7.38      6.25   6.50   7.25     8.13         5.63   4.13   \n",
            "\n",
            "   Durability  Hand-eye coordination  Analytical Aptitude   Total  Rank  \n",
            "0        8.50                    7.0                 5.63  72.375     1  \n",
            "1        8.25                    7.5                 7.50  71.750     2  \n",
            "2        8.50                    5.5                 7.13  68.375     3  \n",
            "3        7.75                    7.5                 7.38  67.875     4  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8391adfe649b>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Tokenization: Split the text into words and sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_words'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "path = \"/content/drive/MyDrive/water/train.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df.head(5))\n",
        "\n",
        "text_column = 'text'\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text = gutenberg.raw('austen-emma.txt')\n",
        "\n",
        "print(\"\\nOriginal Text (first 500 characters):\")\n",
        "print(text[:500])\n",
        "\n",
        "words = word_tokenize(text)\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "print(\"\\nTokenized Words (first 10):\")\n",
        "print(words[:10])\n",
        "print(\"\\nTokenized Sentences (first 2):\")\n",
        "print(sentences[:2])\n",
        "\n",
        "porter = PorterStemmer()\n",
        "stemmed_words = [porter.stem(word) for word in words]\n",
        "\n",
        "print(\"\\nStemmed Words (first 10):\")\n",
        "print(stemmed_words[:10])\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
        "\n",
        "print(\"\\nLemmatized Words (first 10):\")\n",
        "print(lemmatized_words[:10])\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in lemmatized_words if word.lower() not in stop_words]\n",
        "\n",
        "print(\"\\nFiltered Words (first 10):\")\n",
        "print(filtered_words[:10])\n",
        "\n",
        "print(\"\\nDiscussion on the impact of each preprocessing step:\")\n",
        "print(\"\\nTokenization:\")\n",
        "print(\"Tokenization splits the text into smaller units such as words and sentences. This is the fundamental step for any text processing task as it breaks down the text into manageable pieces.\")\n",
        "\n",
        "print(\"\\nStemming:\")\n",
        "print(\"Stemming reduces words to their root form. This helps in reducing the vocabulary size and focuses on the core meaning of the words. However, stemming can sometimes produce non-dictionary words (e.g., 'running' becomes 'run').\")\n",
        "\n",
        "print(\"\\nLemmatization:\")\n",
        "print(\"Lemmatization reduces words to their base or dictionary form. It is more accurate than stemming as it considers the context of the word. For example, 'better' is lemmatized to 'good'. This step is crucial for better understanding and analysis of the text.\")\n",
        "\n",
        "print(\"\\nStop Word Removal:\")\n",
        "print(\"Stop word removal eliminates common words that do not carry significant meaning and are often redundant in text analysis. This step helps in focusing on the more meaningful words in the corpus.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpvj77jLjMsX",
        "outputId": "8ec31fad-049c-48a5-e60d-37b50a216a16"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Original DataFrame:\n",
            "   id  label                                              tweet\n",
            "0   1      0   @user when a father is dysfunctional and is s...\n",
            "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
            "2   3      0                                bihday your majesty\n",
            "3   4      0  #model   i love u take with u all the time in ...\n",
            "4   5      0             factsguide: society now    #motivation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Text (first 500 characters):\n",
            "[Emma by Jane Austen 1816]\n",
            "\n",
            "VOLUME I\n",
            "\n",
            "CHAPTER I\n",
            "\n",
            "\n",
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
            "and happy disposition, seemed to unite some of the best blessings\n",
            "of existence; and had lived nearly twenty-one years in the world\n",
            "with very little to distress or vex her.\n",
            "\n",
            "She was the youngest of the two daughters of a most affectionate,\n",
            "indulgent father; and had, in consequence of her sister's marriage,\n",
            "been mistress of his house from a very early period.  Her mother\n",
            "had died t\n",
            "\n",
            "Tokenized Words (first 10):\n",
            "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']\n",
            "\n",
            "Tokenized Sentences (first 2):\n",
            "['[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.', \"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.\"]\n",
            "\n",
            "Stemmed Words (first 10):\n",
            "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volum', 'i', 'chapter']\n",
            "\n",
            "Lemmatized Words (first 10):\n",
            "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volum', 'i', 'chapter']\n",
            "\n",
            "Filtered Words (first 10):\n",
            "['[', 'emma', 'jane', 'austen', '1816', ']', 'volum', 'chapter', 'emma', 'woodhous']\n",
            "\n",
            "Discussion on the impact of each preprocessing step:\n",
            "\n",
            "Tokenization:\n",
            "Tokenization splits the text into smaller units such as words and sentences. This is the fundamental step for any text processing task as it breaks down the text into manageable pieces.\n",
            "\n",
            "Stemming:\n",
            "Stemming reduces words to their root form. This helps in reducing the vocabulary size and focuses on the core meaning of the words. However, stemming can sometimes produce non-dictionary words (e.g., 'running' becomes 'run').\n",
            "\n",
            "Lemmatization:\n",
            "Lemmatization reduces words to their base or dictionary form. It is more accurate than stemming as it considers the context of the word. For example, 'better' is lemmatized to 'good'. This step is crucial for better understanding and analysis of the text.\n",
            "\n",
            "Stop Word Removal:\n",
            "Stop word removal eliminates common words that do not carry significant meaning and are often redundant in text analysis. This step helps in focusing on the more meaningful words in the corpus.\n"
          ]
        }
      ]
    }
  ]
}